{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist(flag):\n",
    "    with np.load(f\"./data/mnist.npz\") as f:\n",
    "        images, labels = f[f\"x_{flag}\"], f[f\"y_{flag}\"]\n",
    "    images = images.astype(\"float32\") / 255\n",
    "    images = np.reshape(images, (images.shape[0], images.shape[1] * images.shape[2]))\n",
    "    labels = np.eye(10)[labels]\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_mnist(flag=\"train\")\n",
    "X_test, y_test = get_mnist(flag=\"test\")\n",
    "X_val, y_val = X_train[50000:60000,:], y_train[50000:60000] # táº­p validation\n",
    "X_train, y_train = X_train[:50000,:], y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support function\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "def gradient_descent(X, y, theta, alpha, num_iterations):\n",
    "    m = len(y)\n",
    "    num_classes = len(np.unique(y))\n",
    "    for _ in range(num_iterations):\n",
    "        h = softmax(np.dot(X, theta))\n",
    "        gradient = np.dot(X.T, (h - (np.arange(num_classes) == y[:, None]).astype(float))) / m\n",
    "        theta -= alpha * gradient\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "alpha = 0.01\n",
    "num_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros((X_train.shape[1], y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = gradient_descent(X_train, np.argmax(y_train, axis=1), theta, alpha, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned parameters:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Accuracy: 0.872\n"
     ]
    }
   ],
   "source": [
    "# Predictions on the test set\n",
    "test_probabilities = softmax(np.dot(X_test, theta))\n",
    "predictions = np.argmax(test_probabilities, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
